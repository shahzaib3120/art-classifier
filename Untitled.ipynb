{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5378b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import layers, initializers\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.utils import layer_utils\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c246b1b0",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28dcd255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(img, f_size, filters):\n",
    "    F1,F2,F3 = filters\n",
    "    img_shortcut = img\n",
    "    \n",
    "    img = Conv2D(filters=F1, kernel_size=1, strides=(1,1), padding='valid')(img)\n",
    "    img = BatchNormalization(axis=3)(img)\n",
    "    img = Activation('relu')(img)\n",
    "\n",
    "    img = Conv2D(filters=F2, kernel_size=f_size, strides=1, padding=\"same\")(img)\n",
    "    img = BatchNormalization(axis=3)(img)\n",
    "    img = Activation('relu')(img)\n",
    "\n",
    "    img = Conv2D(filters=F3, kernel_size=1, strides=1, padding=\"valid\")(img)\n",
    "    img = BatchNormalization(axis=3)(img)\n",
    "\n",
    "    img = Add()([img, img_shortcut])\n",
    "    img = Activation('relu')(img)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cd9f766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(img, f_size, filters, s=2):\n",
    "    F1,F2,F3 = filters\n",
    "    img_shortcut = img\n",
    "\n",
    "    img = Conv2D(filters=F1, kernel_size=1, strides=s)(img)\n",
    "    img = BatchNormalization(axis=3)(img)\n",
    "    img = Activation('relu')(img)\n",
    "\n",
    "    img = Conv2D(filters=F2, kernel_size=f_size, strides=1, padding=\"same\")(img)\n",
    "    img = BatchNormalization(axis=3)(img)\n",
    "    img = Activation('relu')(img)\n",
    "\n",
    "    img = Conv2D(filters=F3, kernel_size=1, strides=1, padding=\"valid\")(img)\n",
    "    img = BatchNormalization(axis=3)(img)\n",
    "\n",
    "    img_shortcut = Conv2D(F3, 1, s, padding='valid')(img_shortcut)\n",
    "    img = BatchNormalization(axis=3)(img)\n",
    "\n",
    "    img = Add()([img, img_shortcut])\n",
    "    img = Activation('relu')(img)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4b07b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape=(224,224,3),classes = 25):\n",
    "    img_input = Input(input_shape)\n",
    "\n",
    "    img = ZeroPadding2D((3,3))(img_input)\n",
    "\n",
    "    #1\n",
    "    img = Conv2D(64,7,2)(img)\n",
    "    img = BatchNormalization(axis=3)(img)\n",
    "    img = Activation('relu')(img)\n",
    "    img = MaxPooling2D((3,3),strides=(2,2))(img)\n",
    "\n",
    "    #2\n",
    "    img = convolutional_block(img, 3, [64,64,256])\n",
    "    img = identity_block(img, 3, [64,64,256])\n",
    "    img = identity_block(img, 3, [64,64,256])\n",
    "\n",
    "    #3\n",
    "    img = convolutional_block(img, 3, [128,128,512])\n",
    "    img = identity_block(img, 3, [128,128,512])\n",
    "    img = identity_block(img, 3, [128,128,512])\n",
    "    img = identity_block(img, 3, [128,128,512])\n",
    "    \n",
    "    #4\n",
    "    img = convolutional_block(img, 3, [256,256,1024])\n",
    "    img = identity_block(img, 3, [256,256,1024])\n",
    "    img = identity_block(img, 3, [256,256,1024])\n",
    "    img = identity_block(img, 3, [256,256,1024])\n",
    "    img = identity_block(img, 3, [256,256,1024])\n",
    "    img = identity_block(img, 3, [256,256,1024])\n",
    "\n",
    "    #5\n",
    "    img = convolutional_block(img, 3, [512,512,2048])\n",
    "    img = identity_block(img, 3, [512,512,2048])\n",
    "    img = identity_block(img, 3, [512,512,2048])\n",
    "\n",
    "    #avgpool\n",
    "    img = AveragePooling2D((2,2),name=\"avgpool\")(img)\n",
    "\n",
    "\n",
    "    #output_layer\n",
    "    img = Flatten()(img)\n",
    "    img = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer=glorot_uniform(seed=0))(img)\n",
    "\n",
    "    #model\n",
    "    model = Model(inputs= img_input, outputs= img, name=\"ResNet50\")\n",
    "\n",
    "    return model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2093feee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 16:30:59.021485: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-01-20 16:30:59.021616: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tukl): /proc/driver/nvidia/version does not exist\n",
      "2022-01-20 16:30:59.023337: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#model = ResNet50(((224,224,1))) # FOR HOG FEAUTURES\n",
    "model = ResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ea8319b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f0f169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy', metrics.top_k_categorical_accuracy])\n",
    "# tf dataset\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ae0bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c322ccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from contextlib import redirect_stdout\n",
    "\n",
    "# with open('summary.txt', 'w') as f:\n",
    "#     with redirect_stdout(f):\n",
    "#         model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333a7fb8",
   "metadata": {},
   "source": [
    "<h1>Data Collection</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448230b6",
   "metadata": {},
   "source": [
    "# Numpy Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979c964f",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b35ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "from keras.preprocessing.image import load_img\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "use_HOG = True\n",
    "print (\"Using HOG \" , end=\"\")\n",
    "print(\"True\") if use_HOG else print(\"False\")\n",
    "img_size = (224,224) \n",
    "data_path = \"./data/wikipaintings_small/wikipaintings_train\"\n",
    "class_names = os.listdir(data_path)\n",
    "img_data = []\n",
    "x_train = []\n",
    "y_train = []\n",
    "classes = []\n",
    "for class_name in class_names:\n",
    "    class_path = join(data_path, class_name)\n",
    "    img_names = os.listdir(class_path)\n",
    "    classes.append(class_name)\n",
    "    for img_name in img_names:\n",
    "        img = load_img(join(class_path, img_name),target_size=img_size)\n",
    "        if use_HOG == True :\n",
    "            fd, hog_image = hog(img, orientations=9, pixels_per_cell=(8, 8),cells_per_block=(2, 2), visualize=True, multichannel=True)\n",
    "            img_arr = img_to_array(hog_image)\n",
    "        else:\n",
    "            img_arr = img_to_array(img)\n",
    "            \n",
    "        x_train.append(img_arr)\n",
    "        y_train.append(class_name)\n",
    "        # img_data.append((class_name, join(class_path,img_name)))\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_train = x_train.astype('float32')/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5726861a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b33fd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfe02e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36897af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "transfomed_label = encoder.fit_transform(y_train)\n",
    "print(transfomed_label)\n",
    "transfomed_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2215763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# imgs_df = pd.DataFrame(data=img_data, columns=['class', 'image'])\n",
    "# print(imgs_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc808266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bb1611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(imgs_df['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b8b6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# y=imgs_df['class'].values\n",
    "# print(y[:15])\n",
    "# print(y_train[:15])\n",
    "\n",
    "# y_labelenc = LabelEncoder()\n",
    "# y=y_labelenc.fit_transform(y)\n",
    "\n",
    "# y=y.reshape(-1,1)\n",
    "# onehotenc = OneHotEncoder(categorical_features=[0])\n",
    "# Y=onehotenc.fit_transform(y)\n",
    "# Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ccc502",
   "metadata": {},
   "source": [
    "## Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe962fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "from keras.preprocessing.image import load_img\n",
    "img_size = (224,224) \n",
    "data_path = \"../rasta/data/wikipaintings_small/wikipaintings_test\"\n",
    "class_names = os.listdir(data_path)\n",
    "x_test = []\n",
    "y_test = []\n",
    "for class_name in class_names:\n",
    "    class_path = join(data_path, class_name)\n",
    "    img_names = os.listdir(class_path)\n",
    "    classes.append(class_name)\n",
    "    for img_name in img_names:\n",
    "        img = load_img(join(class_path, img_name),target_size=img_size)\n",
    "        if use_HOG == True :\n",
    "            fd, hog_image = hog(img, orientations=9, pixels_per_cell=(8, 8),cells_per_block=(2, 2), visualize=True, multichannel=True)\n",
    "            img_arr = img_to_array(hog_image)\n",
    "        else:\n",
    "            img_arr = img_to_array(img)\n",
    "        \n",
    "        x_test.append(img_arr)\n",
    "        y_test.append(class_name)\n",
    "x_test = np.array(x_train)\n",
    "y_test = np.array(y_train)\n",
    "x_test = x_train.astype('float32')/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1554fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "print(y_test)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4e5c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97234d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09c536df",
   "metadata": {},
   "source": [
    "# TF DATASETS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecaf4c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(data_dir=\"./data/wikipaintings_small/wikipaintings_train\", img_size=(224,224),batch_size=50):\n",
    "#     data_dir = \"./data/wikipaintings_small/wikipaintings_train\"\n",
    "#     img_height = 224\n",
    "#     img_width = 224\n",
    "#     batch_size = 50\n",
    "    \n",
    "    #training\n",
    "    \n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "#     validation_split=0.2,\n",
    "#     subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "    # validation \n",
    "    \n",
    "#     val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#     data_dir,\n",
    "#     validation_split=0.2,\n",
    "#     subset=\"validation\",\n",
    "#     seed=123,\n",
    "#     image_size=img_size,\n",
    "#     batch_size=batch_size)\n",
    "    \n",
    "    #normalization \n",
    "    \n",
    "    normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "    normalized_train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "    \n",
    "    # normalization of val dataset\n",
    "    \n",
    "#     normalized_val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "#     image_batch, labels_batch = next(iter(normalized_train_ds))\n",
    "#     first_image = image_batch[0]\n",
    "    # Notice the pixel values are now in `[0,1]`.\n",
    "    \n",
    "#     print(np.min(first_image), np.max(first_image))\n",
    "    \n",
    "    for image_batch, labels_batch in train_ds:\n",
    "        print(image_batch.shape)\n",
    "        print(labels_batch.shape)\n",
    "        break\n",
    "    return normalized_train_ds\n",
    "#     return normalized_train_ds, normalized_val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7f798d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 250 files belonging to 25 classes.\n",
      "(50, 224, 224, 3)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "# train_ds, val_ds = get_datasets()\n",
    "train_ds = get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d743ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71ee8c21",
   "metadata": {},
   "source": [
    "## Test Data using TF DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f326f0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fb13c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([50, 224, 224, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_batch, labels_batch = next(iter(train_ds))\n",
    "image_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033d12bb",
   "metadata": {},
   "source": [
    "## Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f478f250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 18s 3s/step - loss: 4.6469 - accuracy: 0.0840\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 18s 3s/step - loss: 3.5115 - accuracy: 0.0920\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 16s 3s/step - loss: 3.3698 - accuracy: 0.1320\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 17s 3s/step - loss: 3.7140 - accuracy: 0.1800\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 19s 4s/step - loss: 3.1302 - accuracy: 0.1680\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 20s 4s/step - loss: 2.5940 - accuracy: 0.2240\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 21s 4s/step - loss: 2.7114 - accuracy: 0.2200\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 20s 4s/step - loss: 2.6833 - accuracy: 0.2440\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 18s 4s/step - loss: 2.6848 - accuracy: 0.2640\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 19s 4s/step - loss: 2.6449 - accuracy: 0.2960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc8cf3d1e20>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tain_img, labels, )\n",
    "model.fit(train_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "503ab814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 610ms/step - loss: 4688.5986 - accuracy: 0.0400\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(val_ds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f1e192",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ResNet50xHOG.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f507ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-image"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ddfba760c93d0781cb88c4db9a31eb68ca4e1616821530f19d735f356a5c9ec"
  },
  "kernelspec": {
   "display_name": "Python (art-classifier)",
   "language": "python",
   "name": "art-classifier"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
